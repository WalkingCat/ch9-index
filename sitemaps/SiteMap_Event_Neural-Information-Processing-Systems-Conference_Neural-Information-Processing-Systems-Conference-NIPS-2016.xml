<?xml version="1.0" encoding="UTF-8" ?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:video="http://www.google.com/schemas/sitemap-video/1.1">
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016</loc>
      <lastmod>2021-10-30</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.5</priority>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Large-Scale-Optimization-Beyond-Stochastic-Gradient-Descent-and-Convexity</loc>
      <lastmod>2017-06-07</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/0e6d/c86246c0-3d71-42cd-a146-469a546b0e6d/BachSra_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Large-Scale Optimization: Beyond Stochastic Gradient Descent and Convexity]]></video:title>
        <video:description><![CDATA[Stochastic optimization lies at the heart of machine learning, and its cornerstone is stochastic gradient descent (SGD), a staple introduced over 60 years ago! Recent years have, however, brought an&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/0e6d/c86246c0-3d71-42cd-a146-469a546b0e6d/BachSra_mid.mp4</video:content_loc>
        <video:duration>6955</video:duration>
        <video:publication_date>2017-06-07T22:19:41.5171357+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Machine-Learning-and-the-Law-Symposium-Session-1</loc>
      <lastmod>2017-04-25</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/cb39/60ad7aa7-eb61-4f39-bc07-9a41d24dcb39/symposium2Law1_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Machine Learning and the Law Symposium Session 1]]></video:title>
        <video:description><![CDATA[Advances in machine learning and artificial intelligence mean that predictions and decisions of algorithms are already in use in many important situations under legal or regulatory control, and this&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/cb39/60ad7aa7-eb61-4f39-bc07-9a41d24dcb39/symposium2Law1_mid.mp4</video:content_loc>
        <video:duration>6810</video:duration>
        <video:publication_date>2017-04-24T22:07:21.0012706+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Nuts-and-Bolts-of-Building-Applications-using-Deep-Learning</loc>
      <lastmod>2017-08-09</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/443b/a2a1c2f7-9740-4af8-a3e2-9faa63ff443b/Ng_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Nuts and Bolts of Building Applications using Deep Learning]]></video:title>
        <video:description><![CDATA[How do you get deep learning to work in your business, product, or scientific study? The rise of highly scalable deep learning techniques is changing how you can best approach AI problems. This&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/443b/a2a1c2f7-9740-4af8-a3e2-9faa63ff443b/Ng_mid.mp4</video:content_loc>
        <video:duration>7614</video:duration>
        <video:publication_date>2017-04-24T21:54:50.6911113+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Machine-Learning-and-the-Law-Symposium-Session-3</loc>
      <lastmod>2017-04-24</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/29e4/7bdee2ed-c49c-4fc2-88ae-4d332e7729e4/SymposiumMachineLawPart3_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Machine Learning and the Law Symposium Session 3]]></video:title>
        <video:description><![CDATA[Advances in machine learning and artificial intelligence mean that predictions and decisions of algorithms are already in use in many important situations under legal or regulatory control, and this&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/29e4/7bdee2ed-c49c-4fc2-88ae-4d332e7729e4/SymposiumMachineLawPart3_mid.mp4</video:content_loc>
        <video:duration>5488</video:duration>
        <video:publication_date>2017-04-24T19:42:58.1720648+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Machine-Learning-and-the-Law-Symposium-Session-2</loc>
      <lastmod>2017-04-24</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/327f/2f568dd7-55ee-4082-b6b7-9601a3a0327f/MLLaw2_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Machine Learning and the Law Symposium Session 2]]></video:title>
        <video:description><![CDATA[Advances in machine learning and artificial intelligence mean that predictions and decisions of algorithms are already in use in many important situations under legal or regulatory control, and this&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/327f/2f568dd7-55ee-4082-b6b7-9601a3a0327f/MLLaw2_mid.mp4</video:content_loc>
        <video:duration>6453</video:duration>
        <video:publication_date>2017-04-24T15:51:01.6893951+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Recurrent-Neural-Networks-and-Other-Machines-that-Learn-Algorithms-Symposium-Session-3</loc>
      <lastmod>2017-03-16</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/da8b/e68e7a19-38dd-4b50-8bc2-2f733223da8b/RecurrentNeuralNetworksandOtherMachinesthatLearnA_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Recurrent Neural Networks and Other Machines that Learn Algorithms Symposium Session 3]]></video:title>
        <video:description><![CDATA[Soon after the birth of modern computer science in the 1930s, two fundamental questions arose: 1. How can computers learn useful programs from experience, as opposed to being programmed by human&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/da8b/e68e7a19-38dd-4b50-8bc2-2f733223da8b/RecurrentNeuralNetworksandOtherMachinesthatLearnA_mid.mp4</video:content_loc>
        <video:duration>5295</video:duration>
        <video:publication_date>2017-03-16T17:43:45.7499952+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Recurrent-Neural-Networks-and-Other-Machines-that-Learn-Algorithms-Symposium-Session-1</loc>
      <lastmod>2017-03-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/51c7/4e5e36ba-af76-4f32-a342-c736211f51c7/RecurrentNeuralNetworksandOtherMachinesthatLearnA_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Recurrent Neural Networks and Other Machines that Learn Algorithms Symposium Session 1]]></video:title>
        <video:description><![CDATA[Soon after the birth of modern computer science in the 1930s, two fundamental questions arose: 1. How can computers learn useful programs from experience, as opposed to being programmed by human&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/51c7/4e5e36ba-af76-4f32-a342-c736211f51c7/RecurrentNeuralNetworksandOtherMachinesthatLearnA_mid.mp4</video:content_loc>
        <video:duration>6835</video:duration>
        <video:publication_date>2017-03-01T18:42:41.3443749+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Recurrent-Neural-Networks-and-Other-Machines-that-Learn-Algorithms-Symposium-Session-2</loc>
      <lastmod>2017-02-27</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/efab/9720aa69-e4b1-4593-95a7-baba0595efab/Recurrent2_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Recurrent Neural Networks and Other Machines that Learn Algorithms Symposium Session 2]]></video:title>
        <video:description><![CDATA[Soon after the birth of modern computer science in the 1930s, two fundamental questions arose: 1. How can computers learn useful programs from experience, as opposed to being programmed by human&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/efab/9720aa69-e4b1-4593-95a7-baba0595efab/Recurrent2_mid.mp4</video:content_loc>
        <video:duration>6395</video:duration>
        <video:publication_date>2017-02-27T17:02:37.9775293+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Reinforcement-Learning-Through-Policy-Optimization</loc>
      <lastmod>2017-12-21</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/045d/94e12d70-3c8f-467f-a5f6-d5b1f865045d/DeepReinforcementLearningThroughPolicyOptimizatio_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Deep Reinforcement Learning Through Policy Optimization]]></video:title>
        <video:description><![CDATA[Reinforcement Learning (Deep RL) has seen several breakthroughs in recent years. In this tutorial we will focus on recent advances in Deep RL through policy gradient methods and actor critic methods.&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/045d/94e12d70-3c8f-467f-a5f6-d5b1f865045d/DeepReinforcementLearningThroughPolicyOptimizatio_mid.mp4</video:content_loc>
        <video:duration>7146</video:duration>
        <video:publication_date>2017-01-23T19:13:33.6821013+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Theory-and-Algorithms-for-Forecasting-Non-Stationary-Time-Series</loc>
      <lastmod>2017-04-10</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/388d/feeee505-9d2a-4b8e-9df5-133dfa3f388d/VitalyMehryar_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Theory and Algorithms for Forecasting Non-Stationary Time Series]]></video:title>
        <video:description><![CDATA[Time series appear in a variety of key real-world applications such as signal processing, including audio and video processing; the analysis of natural phenomena such as local weather, global&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/388d/feeee505-9d2a-4b8e-9df5-133dfa3f388d/VitalyMehryar_mid.mp4</video:content_loc>
        <video:duration>6304</video:duration>
        <video:publication_date>2017-01-23T19:13:04.2401094+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Crowdsourcing-Beyond-Label-Generation</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/efe7/1dfa805f-fd73-47a5-91fe-2fbf49c7efe7/Vaughan_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Crowdsourcing: Beyond Label Generation]]></video:title>
        <video:description><![CDATA[This tutorial will showcase some of the most innovative uses of crowdsourcing that have emerged in the past few years. While some have clear and immediate benefits to machine learning, we will also&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/efe7/1dfa805f-fd73-47a5-91fe-2fbf49c7efe7/Vaughan_mid.mp4</video:content_loc>
        <video:duration>6618</video:duration>
        <video:publication_date>2017-01-23T19:11:36.9459527+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/ML-Foundations-and-Methods-for-Precision-Medicine-and-Healthcare</loc>
      <lastmod>2017-04-11</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/48f0/5bbb949b-dec2-4daf-b0e6-6ac7cc4848f0/SariaSchulam_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[ML Foundations and Methods for Precision Medicine and Healthcare]]></video:title>
        <video:description><![CDATA[Electronic health records and high throughput measurement technologies are changing the practice of healthcare to become more algorithmic and data-driven. This offers an exciting opportunity for&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/48f0/5bbb949b-dec2-4daf-b0e6-6ac7cc4848f0/SariaSchulam_mid.mp4</video:content_loc>
        <video:duration>7697</video:duration>
        <video:publication_date>2017-01-23T19:09:20.5646288+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Variational-Inference-Foundations-and-Modern-Methods</loc>
      <lastmod>2017-04-10</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/ce50/89dc37af-7514-4e40-9c19-affec1b6ce50/BleiRanganathMohamed_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Variational Inference: Foundations and Modern Methods]]></video:title>
        <video:description><![CDATA[One of the core problems of modern statistics and machine learning is to approximate difficult-to-compute probability distributions. This problem is especially important in probabilistic modeling,&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/ce50/89dc37af-7514-4e40-9c19-affec1b6ce50/BleiRanganathMohamed_mid.mp4</video:content_loc>
        <video:duration>6784</video:duration>
        <video:publication_date>2017-01-23T19:08:34.6657621+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks</loc>
      <lastmod>2017-12-18</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/6b3d/57930795-7f62-4218-8e18-888623426b3d/Goodfellow_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Generative Adversarial Networks]]></video:title>
        <video:description><![CDATA[Generative adversarial networks (GANs) are a recently introduced class of generative models, designed to produce realistic samples. This tutorial is intended to be accessible to an audience who has no&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/6b3d/57930795-7f62-4218-8e18-888623426b3d/Goodfellow_mid.mp4</video:content_loc>
        <video:duration>6953</video:duration>
        <video:publication_date>2017-01-23T19:02:16.3944253+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Predictive-Learning</loc>
      <lastmod>2017-04-10</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/5c00/860be7da-9672-4813-9530-9e9369085c00/Yann_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Predictive Learning]]></video:title>
        <video:description><![CDATA[Deep learning has been at the root of significant progress in many application areas, such as computer perception and natural language processing. But almost all of these systems currently use&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/5c00/860be7da-9672-4813-9530-9e9369085c00/Yann_mid.mp4</video:content_loc>
        <video:duration>3412</video:duration>
        <video:publication_date>2017-01-23T19:01:10.6815268+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Intelligent-Biosphere</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/39dd/797ba269-15aa-47b5-b830-92b93da739dd/Purves_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Intelligent Biosphere]]></video:title>
        <video:description><![CDATA[The biosphere is a stupendously complex and poorly understood system, which we depend on for our survival, and which we are attacking on every front. Worrying. But what has that got to do with machine&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/39dd/797ba269-15aa-47b5-b830-92b93da739dd/Purves_mid.mp4</video:content_loc>
        <video:duration>2982</video:duration>
        <video:publication_date>2017-01-23T18:59:51.5237245+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Value-Iteration-Networks</loc>
      <lastmod>2017-01-28</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/653e/6d6df5bc-bdea-4564-8119-459fdb1b653e/VIN_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Value Iteration Networks]]></video:title>
        <video:description><![CDATA[We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module&#39; embedded within. VINs can learn to plan, and are suitable for predicting outcomes that&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/653e/6d6df5bc-bdea-4564-8119-459fdb1b653e/VIN_mid.mp4</video:content_loc>
        <video:duration>1180</video:duration>
        <video:publication_date>2017-01-23T18:59:27.3270385+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Tractable-Operations-for-Arithmetic-Circuits-of-Probabilistic-Models</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/06c6/cd30c70c-8cb0-4711-996c-9512d1fa06c6/ShenChoiDarwiche_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Tractable Operations for Arithmetic Circuits of Probabilistic Models]]></video:title>
        <video:description><![CDATA[We consider tractable representations of probability distributions and the polytime operations they support. In particular, we consider a recently proposed arithmetic circuit representation, the&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/06c6/cd30c70c-8cb0-4711-996c-9512d1fa06c6/ShenChoiDarwiche_mid.mp4</video:content_loc>
        <video:duration>1155</video:duration>
        <video:publication_date>2017-01-23T18:59:00.6694348+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Testing-for-Differences-in-Gaussian-Graphical-Models-Applications-to-Brain-Connectivity</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/030a/096e21a0-1f87-44d8-8ee2-623aa731030a/Belilovsky_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Testing for Differences in Gaussian Graphical Models: Applications to Brain Connectivity]]></video:title>
        <video:description><![CDATA[Functional brain networks are well described and estimated from data with Gaussian Graphical Models (GGMs), e.g.\ using sparse inverse covariance estimators. Comparing functional connectivity of&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/030a/096e21a0-1f87-44d8-8ee2-623aa731030a/Belilovsky_mid.mp4</video:content_loc>
        <video:duration>1011</video:duration>
        <video:publication_date>2017-01-23T18:58:26.9366121+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/SDP-Relaxation-with-Randomized-Rounding-for-Energy-Disaggregation</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/ce7a/a2aff902-6a98-4e57-90f9-cc526aaece7a/Shaloudegi_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[SDP Relaxation with Randomized Rounding for Energy Disaggregation]]></video:title>
        <video:description><![CDATA[We develop a scalable, computationally efficient method for the task of energy disaggregation for home appliance monitoring. In this problem the goal is to estimate the energy consumption of each&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/ce7a/a2aff902-6a98-4e57-90f9-cc526aaece7a/Shaloudegi_mid.mp4</video:content_loc>
        <video:duration>1296</video:duration>
        <video:publication_date>2017-01-23T18:58:06.2429366+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Bayesian-Intermittent-Demand-Forecasting-for-Large-Inventories</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/83be/6a8f841a-0831-497e-bb38-eb3d1cf583be/Seeger_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Bayesian Intermittent Demand Forecasting for Large Inventories]]></video:title>
        <video:description><![CDATA[We present a scalable and robust Bayesian method for demand forecasting in the context of a large e-commerce platform, paying special attention to intermittent and bursty target statistics. Inference&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/83be/6a8f841a-0831-497e-bb38-eb3d1cf583be/Seeger_mid.mp4</video:content_loc>
        <video:duration>1081</video:duration>
        <video:publication_date>2017-01-23T18:57:33.0364093+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Synthesis-of-MCMC-and-Belief-Propagation</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/4f64/8e298fe2-589e-4f16-961c-3a37d7e14f64/Ahn_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Synthesis of MCMC and Belief Propagation]]></video:title>
        <video:description><![CDATA[Markov Chain Monte Carlo (MCMC) and Belief Propagation (BP) are the most popular algorithms for computational inference in Graphical Models (GM). In principle, MCMC is an exact probabilistic method&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/4f64/8e298fe2-589e-4f16-961c-3a37d7e14f64/Ahn_mid.mp4</video:content_loc>
        <video:duration>1046</video:duration>
        <video:publication_date>2017-01-23T18:56:53.7279037+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Learning-for-Predicting-Human-Strategic-Behavior</loc>
      <lastmod>2017-02-03</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/e713/7446746e-1923-4e18-9a73-1ff4ed32e713/DeepLearningforPredictingHumanStrategicBehavior_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Deep Learning for Predicting Human Strategic Behavior]]></video:title>
        <video:description><![CDATA[Predicting the behavior of human participants in strategic settings is an important problem in many domains. Most existing work either assumes that participants are perfectly rational, or attempts to&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/e713/7446746e-1923-4e18-9a73-1ff4ed32e713/DeepLearningforPredictingHumanStrategicBehavior_mid.mp4</video:content_loc>
        <video:duration>1159</video:duration>
        <video:publication_date>2017-01-23T18:55:35.6511819+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Using-Fast-Weights-to-Attend-to-the-Recent-Past</loc>
      <lastmod>2017-01-29</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/4faf/8c363686-df2d-4d30-bf50-8269acf34faf/Bu_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Using Fast Weights to Attend to the Recent Past]]></video:title>
        <video:description><![CDATA[Until recently, research on artificial neural networks was largely restricted to systems with only two types of variable: Neural activities that represent the current or recent input and weights that&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/4faf/8c363686-df2d-4d30-bf50-8269acf34faf/Bu_mid.mp4</video:content_loc>
        <video:duration>1262</video:duration>
        <video:publication_date>2017-01-23T18:54:56.1295578+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Sequential-Neural-Models-with-Stochastic-Layers</loc>
      <lastmod>2017-09-30</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/e7e0/b24ba1d4-0307-41dc-a2c1-8b75f9b5e7e0/Fraccaro_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Sequential Neural Models with Stochastic Layers]]></video:title>
        <video:description><![CDATA[How can we efficiently propagate uncertainty in a latent state representation with recurrent neural networks? This paper introduces stochastic recurrent neural networks which glue a deterministic&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/e7e0/b24ba1d4-0307-41dc-a2c1-8b75f9b5e7e0/Fraccaro_mid.mp4</video:content_loc>
        <video:duration>1218</video:duration>
        <video:publication_date>2017-01-23T18:54:15.9758690+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Phased-LSTM-Accelerating-Recurrent-Network-Training-for-Long-or-Event-based-Sequences</loc>
      <lastmod>2017-03-02</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/6bf5/880282e4-7e13-4046-81a5-6ca89ab96bf5/Niel_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences]]></video:title>
        <video:description><![CDATA[Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. Current RNN models are ill suited to process irregularly sampled data&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/6bf5/880282e4-7e13-4046-81a5-6ca89ab96bf5/Niel_mid.mp4</video:content_loc>
        <video:duration>1255</video:duration>
        <video:publication_date>2017-01-23T18:50:09.9614607+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Graphons-mergeons-and-so-on</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/bde8/f3c2f6ed-09f4-4ad0-ba2f-e4bd0293bde8/Eldridge_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Graphons, mergeons, and so on!]]></video:title>
        <video:description><![CDATA[In this work we develop a theory of hierarchical clustering for graphs. Our modelling assumption is that graphs are sampled from a graphon, which is a powerful and general model for generating graphs&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/bde8/f3c2f6ed-09f4-4ad0-ba2f-e4bd0293bde8/Eldridge_mid.mp4</video:content_loc>
        <video:duration>1030</video:duration>
        <video:publication_date>2017-01-23T18:49:38.3611509+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Hierarchical-Clustering-via-Spreading-Metrics</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/7cd5/c95e4d32-3701-4f01-aa44-f9f47e0d7cd5/Roy_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Hierarchical Clustering via Spreading Metrics]]></video:title>
        <video:description><![CDATA[We study the cost function for hierarchical clusterings introduced by [Dasgupta, 2015] where hierarchies are treated as first-class objects rather than deriving their cost from projections into flat&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/7cd5/c95e4d32-3701-4f01-aa44-f9f47e0d7cd5/Roy_mid.mp4</video:content_loc>
        <video:duration>1060</video:duration>
        <video:publication_date>2017-01-23T18:48:58.5260698+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Clustering-with-Same-Cluster-Queries</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/2a94/75494bf6-d567-4e85-a6c2-ef017adf2a94/Ashtiani_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Clustering with Same-Cluster Queries]]></video:title>
        <video:description><![CDATA[We propose a framework for Semi-Supervised Active Clustering framework (SSAC), where the learner is allowed to interact with a domain expert, asking whether two given instances belong to the same&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/2a94/75494bf6-d567-4e85-a6c2-ef017adf2a94/Ashtiani_mid.mp4</video:content_loc>
        <video:duration>1085</video:duration>
        <video:publication_date>2017-01-23T18:48:25.4856139+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Unsupervised-Feature-Extraction-by-Time-Contrastive-Learning-and-Nonlinear-ICA</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/4095/a0070345-b608-4990-a10b-9cf7e4404095/Hyvarinen_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA]]></video:title>
        <video:description><![CDATA[Nonlinear independent component analysis (ICA) provides an appealing framework for unsupervised feature learning, but the models proposed so far are not identifiable. Here, we first propose a new&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/4095/a0070345-b608-4990-a10b-9cf7e4404095/Hyvarinen_mid.mp4</video:content_loc>
        <video:duration>1370</video:duration>
        <video:publication_date>2017-01-23T18:47:58.4108534+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Fast-and-Provably-Good-Seedings-for-k-Means</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/1f8a/3c5492ca-180a-41f4-aa60-09755a0c1f8a/Bachem_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Fast and Provably Good Seedings for k-Means]]></video:title>
        <video:description><![CDATA[Seeding - the task of finding initial cluster centers - is critical in obtaining high-quality clusterings for k-Means. However, k-means&amp;#43;&amp;#43; seeding, the state of the art algorithm, does not&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/1f8a/3c5492ca-180a-41f4-aa60-09755a0c1f8a/Bachem_mid.mp4</video:content_loc>
        <video:duration>1184</video:duration>
        <video:publication_date>2017-01-23T18:47:37.7557840+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Supervised-learning-through-the-lens-of-compression</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/d13b/50cca4f8-bfe9-47f9-8a41-ca5e3699d13b/Moran_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Supervised learning through the lens of compression]]></video:title>
        <video:description><![CDATA[This work continues the study of the relationship between sample compression schemes and statistical learning, which has been mostly investigated within the framework of binary classification. We&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/d13b/50cca4f8-bfe9-47f9-8a41-ca5e3699d13b/Moran_mid.mp4</video:content_loc>
        <video:duration>1012</video:duration>
        <video:publication_date>2017-01-23T18:47:12.2264863+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/MetaGrad-Multiple-Learning-Rates-in-Online-Learning</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/1435/da1cb27e-22b3-4f65-bb63-0cc697441435/Koolen_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[MetaGrad: Multiple Learning Rates in Online Learning]]></video:title>
        <video:description><![CDATA[In online convex optimization it is well known that certain subclasses of objective functions are much easier than arbitrary convex functions. We are interested in designing adaptive methods that can&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/1435/da1cb27e-22b3-4f65-bb63-0cc697441435/Koolen_mid.mp4</video:content_loc>
        <video:duration>996</video:duration>
        <video:publication_date>2017-01-23T18:46:45.4340445+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Blazing-the-trails-before-beating-the-path-Sample-efficient-Monte-Carlo-planning</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/5bc8/c5253f5e-8d0b-443b-8b4e-8c621cce5bc8/Grill_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning]]></video:title>
        <video:description><![CDATA[We study the sampling-based planning problem in Markov decision processes (MDPs) that we can access only through a generative model, usually referred to as Monte-Carlo planning. Our objective is to&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/5bc8/c5253f5e-8d0b-443b-8b4e-8c621cce5bc8/Grill_mid.mp4</video:content_loc>
        <video:duration>952</video:duration>
        <video:publication_date>2017-01-23T18:46:11.2754443+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Global-Analysis-of-Expectation-Maximization-for-Mixtures-of-Two-Gaussians</loc>
      <lastmod>2017-05-08</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/5fa6/ac070b92-dbb5-4b3f-ad0f-6a5d6af95fa6/Xu_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Global Analysis of Expectation Maximization for Mixtures of Two Gaussians]]></video:title>
        <video:description><![CDATA[Expectation Maximization (EM) is among the most popular algorithms for estimating parameters of statistical models. However, EM, which is an iterative algorithm based on the maximum likelihood&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/5fa6/ac070b92-dbb5-4b3f-ad0f-6a5d6af95fa6/Xu_mid.mp4</video:content_loc>
        <video:duration>1138</video:duration>
        <video:publication_date>2017-01-23T18:45:46.7035993+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Machine-Learning-and-Likelihood-Free-Inference-in-Particle-Physics</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/ce38/540802a3-6367-47f2-aa26-950fc840ce38/Cranmer_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Machine Learning and Likelihood-Free Inference in Particle Physics]]></video:title>
        <video:description><![CDATA[Particle physics aims to answer profound questions about the fundamental building blocks of the Universe through enormous data sets collected at experiments like the Large Hadron Collider at CERN.&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/ce38/540802a3-6367-47f2-aa26-950fc840ce38/Cranmer_mid.mp4</video:content_loc>
        <video:duration>3037</video:duration>
        <video:publication_date>2017-01-23T18:44:42.9939490+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Matrix-Completion-has-No-Spurious-Local-Minimum</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/d101/0399980d-f6c3-4f04-ac17-58dfae41d101/Ma_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Matrix Completion has No Spurious Local Minimum]]></video:title>
        <video:description><![CDATA[Matrix completion is a basic machine learning problem that has wide applications, especially in collaborative filtering and recommender systems. Simple non-convex optimization algorithms are popular&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/d101/0399980d-f6c3-4f04-ac17-58dfae41d101/Ma_mid.mp4</video:content_loc>
        <video:duration>1106</video:duration>
        <video:publication_date>2017-01-23T18:44:04.1412576+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Large-Scale-Price-Optimization-via-Network-Flow</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/83f5/7e060b2e-bf42-436c-8335-28b476e783f5/Ito_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Large-Scale Price Optimization via Network Flow]]></video:title>
        <video:description><![CDATA[This paper deals with price optimization, which is to find the best pricing strategy that maximizes revenue or profit, on the basis of demand forecasting models. Though recent advances in regression&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/83f5/7e060b2e-bf42-436c-8335-28b476e783f5/Ito_mid.mp4</video:content_loc>
        <video:duration>1139</video:duration>
        <video:publication_date>2017-01-23T18:43:39.8848951+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Visual-Dynamics-Probabilistic-Future-Frame-Synthesis-via-Cross-Convolutional-Networks</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/3def/61f3afb4-7a8c-4148-a11c-1439145a3def/Xue_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks]]></video:title>
        <video:description><![CDATA[We study the problem of synthesizing a number of likely future frames from a single input image. In contrast to traditional methods, which have tackled this problem in a deterministic or&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/3def/61f3afb4-7a8c-4148-a11c-1439145a3def/Xue_mid.mp4</video:content_loc>
        <video:duration>1097</video:duration>
        <video:publication_date>2017-01-23T18:41:01.2721608+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Supervised-Word-Movers-Distance</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/5488/23ac60e6-bd89-4a33-ab77-821abf8d5488/Kusner_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Supervised Word Mover&#39;s Distance]]></video:title>
        <video:description><![CDATA[Accurately measuring the similarity between text documents lies at the core of many real world applications of machine learning. These include web-search ranking, document recommendation,&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/5488/23ac60e6-bd89-4a33-ab77-821abf8d5488/Kusner_mid.mp4</video:content_loc>
        <video:duration>1290</video:duration>
        <video:publication_date>2017-01-23T18:40:26.8423483+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Beyond-Exchangeability-The-Chinese-Voting-Process</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/ad1c/3a6cf931-61bc-455c-98c6-7209b002ad1c/Lee_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Beyond Exchangeability: The Chinese Voting Process]]></video:title>
        <video:description><![CDATA[Many online communities present user-contributed responses, such as reviews of products and answers to questions. User-provided helpfulness votes can highlight the most useful responses, but voting is&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/ad1c/3a6cf931-61bc-455c-98c6-7209b002ad1c/Lee_mid.mp4</video:content_loc>
        <video:duration>1174</video:duration>
        <video:publication_date>2017-01-23T18:39:50.6542956+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Protein-contact-prediction-from-amino-acid-co-evolution-using-convolutional-networks-for-graph-value</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/6fc3/94ceae0a-ff4c-45a6-b8d7-e2476bc56fc3/Golkov_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Protein contact prediction from amino acid co-evolution using convolutional networks for&amp;#8230;]]></video:title>
        <video:description><![CDATA[Proteins are the &amp;quot;building blocks of life&amp;quot;, the most abundant organic molecules, and the central focus of most areas of biomedicine. Protein structure is strongly related to protein&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/6fc3/94ceae0a-ff4c-45a6-b8d7-e2476bc56fc3/Golkov_mid.mp4</video:content_loc>
        <video:duration>1212</video:duration>
        <video:publication_date>2017-01-23T18:39:13.9347844+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Learning-without-Poor-Local-Minima</loc>
      <lastmod>2018-10-16</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/dc83/25529631-0674-4590-a0c6-4d0b5e3ddc83/Kawaguchi_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Deep Learning without Poor Local Minima]]></video:title>
        <video:description><![CDATA[In this paper, we prove a conjecture published in 1989 and also partially address an open problem announced at the Conference on Learning Theory (COLT) 2015. For an expected loss function of a deep&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/dc83/25529631-0674-4590-a0c6-4d0b5e3ddc83/Kawaguchi_mid.mp4</video:content_loc>
        <video:duration>1159</video:duration>
        <video:publication_date>2017-01-23T18:38:22.6765673+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Learning-to-Poke-by-Poking-Experiential-Learning-of-Intuitive-Physics</loc>
      <lastmod>2017-11-06</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/2df4/801b969c-dc0b-4b5f-b033-7beca2bb2df4/Agrawal_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Learning to Poke by Poking: Experiential Learning of Intuitive Physics]]></video:title>
        <video:description><![CDATA[We investigate an experiential learning paradigm for acquiring an internal model of intuitive physics. Our model is evaluated on a real-world robotic manipulation task that requires displacing objects&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/2df4/801b969c-dc0b-4b5f-b033-7beca2bb2df4/Agrawal_mid.mp4</video:content_loc>
        <video:duration>1260</video:duration>
        <video:publication_date>2017-01-23T18:36:49.8208649+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Learning-What-and-Where-to-Draw</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/3e9a/087db78b-767a-49b6-b7db-38099bc43e9a/Reed_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Learning What and Where to Draw]]></video:title>
        <video:description><![CDATA[Generative Adversarial Networks (GANs) have recently demonstrated the capability to synthesize compelling real-world images, such as room interiors, album covers, manga, faces, birds, and flowers.&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/3e9a/087db78b-767a-49b6-b7db-38099bc43e9a/Reed_mid.mp4</video:content_loc>
        <video:duration>1297</video:duration>
        <video:publication_date>2017-01-23T18:36:22.4041419+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Weight-Normalization-A-Simple-Reparameterization-to-Accelerate-Training-of-Deep-Neural-Networks</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/5473/29f6b73d-d9ff-4a02-838b-9db4bcf45473/Salimans_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks]]></video:title>
        <video:description><![CDATA[We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/5473/29f6b73d-d9ff-4a02-838b-9db4bcf45473/Salimans_mid.mp4</video:content_loc>
        <video:duration>1375</video:duration>
        <video:publication_date>2017-01-23T18:35:39.9750578+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Achieving-the-KS-threshold-in-the-general-stochastic-block-model-with-linearized-acyclic-belief-prop</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/7940/39bcddee-1773-4224-b38a-ab8714067940/Abbe_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Achieving the KS threshold in the general stochastic block model with linearized acyclic belief&amp;#8230;]]></video:title>
        <video:description><![CDATA[The stochastic block model (SBM) has long been studied in machine learning and network science as a canonical model for clustering and community detection. In the recent years, new developments have&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/7940/39bcddee-1773-4224-b38a-ab8714067940/Abbe_mid.mp4</video:content_loc>
        <video:duration>904</video:duration>
        <video:publication_date>2017-01-23T18:35:14.6369908+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Orthogonal-Random-Features</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/7dc0/e4738613-73a0-4acc-91e6-82117b207dc0/Suresh_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Orthogonal Random Features]]></video:title>
        <video:description><![CDATA[We present an intriguing discovery related to Random Fourier Features: replacing multiplication by a random Gaussian matrix with multiplication by a properly scaled random orthogonal matrix&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/7dc0/e4738613-73a0-4acc-91e6-82117b207dc0/Suresh_mid.mp4</video:content_loc>
        <video:duration>1122</video:duration>
        <video:publication_date>2017-01-23T18:34:45.8210657+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Poisson-Gamma-dynamical-systems</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/25eb/3338a523-df71-4c9a-943f-2ba297ee25eb/Schein_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Poisson-Gamma dynamical systems]]></video:title>
        <video:description><![CDATA[This paper presents a dynamical system based on the Poisson-Gamma construction for sequentially observed multivariate count data. Inherent to the model is a novel Bayesian nonparametric prior that&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/25eb/3338a523-df71-4c9a-943f-2ba297ee25eb/Schein_mid.mp4</video:content_loc>
        <video:duration>1000</video:duration>
        <video:publication_date>2017-01-23T18:34:10.5728057+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/The-Multiscale-Laplacian-Graph-Kernel</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/0e46/e3cc11ec-2a13-4ec5-a9b2-2455c51d0e46/Kondor_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[The Multiscale Laplacian Graph Kernel]]></video:title>
        <video:description><![CDATA[Many real world graphs, such as the graphs of molecules, exhibit structure at multiple different scales, but most existing kernels between graphs are either purely local or purely global in character.&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/0e46/e3cc11ec-2a13-4ec5-a9b2-2455c51d0e46/Kondor_mid.mp4</video:content_loc>
        <video:duration>1234</video:duration>
        <video:publication_date>2017-01-23T18:33:32.9150355+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Stochastic-Online-AUC-Maximization</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/4fe6/39255c10-d7fd-4f88-8c98-5da3913f4fe6/Ying_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Stochastic Online AUC Maximization]]></video:title>
        <video:description><![CDATA[Area under ROC (AUC) is a metric which is widely used for measuring the classification performance for imbalanced data. It is of theoretical and practical interest to develop online learning&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/4fe6/39255c10-d7fd-4f88-8c98-5da3913f4fe6/Ying_mid.mp4</video:content_loc>
        <video:duration>880</video:duration>
        <video:publication_date>2017-01-23T18:33:03.9336136+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Without-Replacement-Sampling-for-Stochastic-Gradient-Methods</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/1d29/da5fed90-9fb1-4505-8fa0-918cad131d29/Shamir_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Without-Replacement Sampling for Stochastic Gradient Methods]]></video:title>
        <video:description><![CDATA[Stochastic gradient methods for machine learning and optimization problems are usually analyzed assuming data points are sampled with replacement. In contrast, sampling without replacement is far less&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/1d29/da5fed90-9fb1-4505-8fa0-918cad131d29/Shamir_mid.mp4</video:content_loc>
        <video:duration>1195</video:duration>
        <video:publication_date>2017-01-23T18:28:23.8879885+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Regularized-Nonlinear-Acceleration</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/c4f9/3f3c40de-0be8-44a6-9f8a-965fcfbfc4f9/Scieur_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Regularized Nonlinear Acceleration]]></video:title>
        <video:description><![CDATA[We describe a convergence acceleration technique for generic optimization problems. Our scheme computes estimates of the optimum from a nonlinear average of the iterates produced by any optimization&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/c4f9/3f3c40de-0be8-44a6-9f8a-965fcfbfc4f9/Scieur_mid.mp4</video:content_loc>
        <video:duration>1132</video:duration>
        <video:publication_date>2017-01-23T18:27:45.9008325+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generalization-of-ERM-in-Stochastic-Convex-Optimization-The-Dimension-Strikes-Back</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/e500/aa07311c-1c41-4365-bf8b-618877ede500/Feldman_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Generalization of ERM in Stochastic Convex Optimization: The Dimension Strikes Back]]></video:title>
        <video:description><![CDATA[In stochastic convex optimization the goal is to minimize a convex function $F(x) \doteq \E{f\sim D}[f(x)]overaconvexset  \K \subset \R^dwhere  Dissomeunknowndistributionandeach &amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/e500/aa07311c-1c41-4365-bf8b-618877ede500/Feldman_mid.mp4</video:content_loc>
        <video:duration>981</video:duration>
        <video:publication_date>2017-01-23T18:26:14.3854526+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Bayesian-Optimization-with-Robust-Bayesian-Neural-Networks</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/6fc0/569f3d1d-1982-4b88-90ef-76f694b76fc0/Springenberg_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Bayesian Optimization with Robust Bayesian Neural Networks]]></video:title>
        <video:description><![CDATA[Bayesian optimization is a prominent method for optimizing expensive to evaluate black-box functions that is prominently applied to tuning the hyperparameters of machine learning algorithms. Despite&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/6fc0/569f3d1d-1982-4b88-90ef-76f694b76fc0/Springenberg_mid.mp4</video:content_loc>
        <video:duration>890</video:duration>
        <video:publication_date>2017-01-23T18:25:09.8899377+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Learning-About-the-Brain-Neuroimaging-and-Beyond</loc>
      <lastmod>2017-02-08</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/f85f/0ea9e0b3-8e8c-4832-8c34-d53ad4e1f85f/Rish_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Learning About the Brain: Neuroimaging and Beyond]]></video:title>
        <video:description><![CDATA[Quantifying mental states and identifying &amp;quot;statistical biomarkers&amp;quot; of mental disorders from neuroimaging data is an exciting and rapidly growing research area at the intersection of&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/f85f/0ea9e0b3-8e8c-4832-8c34-d53ad4e1f85f/Rish_mid.mp4</video:content_loc>
        <video:duration>3097</video:duration>
        <video:publication_date>2017-01-23T18:23:56.1216812+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Reproducible-Research-the-Case-of-the-Human-Microbiome</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/04ea/275bc129-e0f0-4beb-8324-88b8d40b04ea/Holmes_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Reproducible Research: the Case of the Human Microbiome]]></video:title>
        <video:description><![CDATA[Modern data sets usually present multiple levels of heterogeneity, some apparent such as the necessity of combining trees, graphs, contingency tables and continuous covariates, others concern latent&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/04ea/275bc129-e0f0-4beb-8324-88b8d40b04ea/Holmes_mid.mp4</video:content_loc>
        <video:duration>3353</video:duration>
        <video:publication_date>2017-01-23T18:22:26.8018787+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Interpretable-Distribution-Features-with-Maximum-Testing-Power</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/7dc2/9219e4d4-5495-4217-bc14-6f71e4fb7dc2/Jitkrittum_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Interpretable Distribution Features with Maximum Testing Power]]></video:title>
        <video:description><![CDATA[Two semimetrics on probability distributions are proposed, given as the sum of differences of expectations of analytic functions evaluated at spatial or frequency locations (i.e, features). The&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/7dc2/9219e4d4-5495-4217-bc14-6f71e4fb7dc2/Jitkrittum_mid.mp4</video:content_loc>
        <video:duration>1365</video:duration>
        <video:publication_date>2017-01-23T18:20:30.2518565+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Examples-are-not-enough-learn-to-criticize-Criticism-for-Interpretability</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/a683/259e30d7-4ba9-4728-9c79-7c5ca982a683/Kim_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Examples are not enough, learn to criticize! Criticism for Interpretability ]]></video:title>
        <video:description><![CDATA[Example-based explanations are widely used in the effort to improve the interpretability of highly complex distributions. However, prototypes alone are rarely sufficient to represent the gist of the&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/a683/259e30d7-4ba9-4728-9c79-7c5ca982a683/Kim_mid.mp4</video:content_loc>
        <video:duration>1239</video:duration>
        <video:publication_date>2017-01-23T18:18:17.0586548+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Showing-versus-doing-Teaching-by-demonstration</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/9bb7/0cd5e272-42b6-4b11-9d25-6f4943699bb7/Ho_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Showing versus doing: Teaching by demonstration]]></video:title>
        <video:description><![CDATA[People often learn from others&#39; demonstrations, and classic inverse reinforcement learning (IRL) algorithms have brought us closer to realizing this capacity in machines. In contrast, teaching by&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/9bb7/0cd5e272-42b6-4b11-9d25-6f4943699bb7/Ho_mid.mp4</video:content_loc>
        <video:duration>1143</video:duration>
        <video:publication_date>2017-01-23T18:17:18.8321612+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Relevant-sparse-codes-with-variational-information-bottleneck</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/884e/fedded64-92f6-4dee-b6b1-95a0484a884e/Chalk_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Relevant sparse codes with variational information bottleneck]]></video:title>
        <video:description><![CDATA[In many applications, it is desirable to extract only the relevant aspects of data. A principled way to do this is the information bottleneck (IB) method, where one seeks a code that maximises&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/884e/fedded64-92f6-4dee-b6b1-95a0484a884e/Chalk_mid.mp4</video:content_loc>
        <video:duration>1073</video:duration>
        <video:publication_date>2017-01-23T18:16:10.4712544+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Dense-Associative-Memory-for-Pattern-Recognition</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/1467/b2fe2859-127f-486e-b26e-71072aed1467/Krotov_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Dense Associative Memory for Pattern Recognition]]></video:title>
        <video:description><![CDATA[A model of associative memory is studied, which stores and reliably retrieves many more patterns than the number of neurons in the network. We propose a simple duality between this dense associative&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/1467/b2fe2859-127f-486e-b26e-71072aed1467/Krotov_mid.mp4</video:content_loc>
        <video:duration>1451</video:duration>
        <video:publication_date>2017-01-23T18:14:21.1947972+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Learning-Symposium-Session-3</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/44e7/5d9ee1be-6b8e-4fac-bb74-05c4540044e7/DeepLearning3_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Deep Learning Symposium Session 3]]></video:title>
        <video:description><![CDATA[Deep Learning algorithms attempt to discover good representations, at multiple levels of abstraction. Deep Learning is a topic of broad interest, both to researchers who develop new algorithms and&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/44e7/5d9ee1be-6b8e-4fac-bb74-05c4540044e7/DeepLearning3_mid.mp4</video:content_loc>
        <video:duration>4909</video:duration>
        <video:publication_date>2017-01-23T18:01:41.5632167+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Learning-Symposium-Session-2</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/5624/6a31a3d0-daf4-4869-ad32-c3e04c625624/DeepLearning2_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Deep Learning Symposium Session 2]]></video:title>
        <video:description><![CDATA[Deep Learning algorithms attempt to discover good representations, at multiple levels of abstraction. Deep Learning is a topic of broad interest, both to researchers who develop new algorithms and&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/5624/6a31a3d0-daf4-4869-ad32-c3e04c625624/DeepLearning2_mid.mp4</video:content_loc>
        <video:duration>3919</video:duration>
        <video:publication_date>2017-01-23T18:01:27.7317569+00:00</video:publication_date>
      </video:video>
   </url>
  <url>
      <loc>https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Learning-Symposium-Session-1</loc>
      <lastmod>2017-01-23</lastmod>
      <changefreq>daily</changefreq>
      <priority>0.8</priority>
      <video:video>
        <video:thumbnail_loc>http://video.ch9.ms/ch9/9306/0e3de764-7e49-454c-be8c-96e8897b9306/DeepLearning1_220.jpg</video:thumbnail_loc>
        <video:title><![CDATA[Deep Learning Symposium Session 1]]></video:title>
        <video:description><![CDATA[Deep Learning algorithms attempt to discover good representations, at multiple levels of abstraction. Deep Learning is a topic of broad interest, both to researchers who develop new algorithms and&amp;#8230;]]></video:description>
        <video:content_loc>http://video.ch9.ms/ch9/9306/0e3de764-7e49-454c-be8c-96e8897b9306/DeepLearning1_mid.mp4</video:content_loc>
        <video:duration>6879</video:duration>
        <video:publication_date>2017-01-23T18:00:39.1453595+00:00</video:publication_date>
      </video:video>
   </url>
</urlset> 
